{"cells": [{"cell_type": "code", "execution_count": null, "id": "f013b09c-d619-4c43-a623-83300b2588a4", "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession"}, {"cell_type": "code", "execution_count": null, "id": "ab0b95de-f0b1-4f76-b08f-8d6759da6369", "metadata": {}, "outputs": [], "source": "spark = SparkSession.builder \\\n.appName(\"Spark_Table\") \\\n.getOrCreate()"}, {"cell_type": "code", "execution_count": null, "id": "4c2eef52-f7dd-46dd-9c7a-e74894a24280", "metadata": {}, "outputs": [], "source": "df = spark.read \\\n.format('csv')\\\n.option('header','True')\\\n.option('inferSchema','True')\\\n.load('/tmp/customers_1mb.csv')"}, {"cell_type": "code", "execution_count": null, "id": "b786cc1d-6c81-413a-b7ef-69472b1d5ba6", "metadata": {}, "outputs": [], "source": "df.show()"}, {"cell_type": "code", "execution_count": null, "id": "ed5c8caa-c29f-4c2a-924e-44231022e5ed", "metadata": {}, "outputs": [], "source": "df.createOrReplaceTempView('customers')"}, {"cell_type": "code", "execution_count": null, "id": "46313d12-01c3-4320-9d2e-1c4028a21ca2", "metadata": {}, "outputs": [], "source": "df.createTempView('customers')"}, {"cell_type": "code", "execution_count": null, "id": "446e8430-1a68-4a66-8f8b-5619a866a2ff", "metadata": {}, "outputs": [], "source": "spark.sql('select * from customers limit 5').show()"}, {"cell_type": "code", "execution_count": null, "id": "6025f779-284e-4784-ab35-d98c941d6450", "metadata": {}, "outputs": [], "source": "df.createOrReplaceGlobalTempView('global_customers')"}, {"cell_type": "code", "execution_count": null, "id": "4210fafc-a5ed-4b83-bd67-52703fab0054", "metadata": {}, "outputs": [], "source": "spark.sql('select * from global_temp.global_customers limit 5').show()"}, {"cell_type": "code", "execution_count": null, "id": "89fa38e1-f45b-4b84-8801-85d970acad5c", "metadata": {}, "outputs": [], "source": "spark2 = SparkSession.builder \\\n.appName(\"Spark_Table\") \\\n.getOrCreate()"}, {"cell_type": "code", "execution_count": null, "id": "660d7bb2-8d4b-470a-8211-b45d6afa6abc", "metadata": {}, "outputs": [], "source": "spark2.sql('select * from global_temp.global_customers limit 5').show()"}, {"cell_type": "code", "execution_count": null, "id": "ad983177-8182-446e-8558-79d0bcf096fb", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "2699ea93-15df-4034-9ff9-a70ad03b8248", "metadata": {}, "outputs": [], "source": "spark.sql('show databases').show()"}, {"cell_type": "code", "execution_count": null, "id": "1f0bdcf2-234d-46e5-ac84-0549578f127e", "metadata": {}, "outputs": [], "source": "spark.sql('use default')"}, {"cell_type": "code", "execution_count": null, "id": "26a6c2b6-0f4c-48c6-9fe7-e1eb85063fa3", "metadata": {}, "outputs": [], "source": "df.write.format('csv').saveAsTable('default.customers')"}, {"cell_type": "code", "execution_count": null, "id": "d76f44ca-a670-4cc9-ae35-001b4e2fe9f4", "metadata": {}, "outputs": [], "source": "spark.sql('select * from default.customers limit 5').show()"}, {"cell_type": "code", "execution_count": null, "id": "a2572fad-3f84-4a53-9e1f-ae5ece1638c6", "metadata": {}, "outputs": [], "source": "spark.stop()"}, {"cell_type": "code", "execution_count": null, "id": "1593f3da-48e5-4e2a-9f20-80f1dd28308e", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "65f8cc3a-6ba8-45ce-87a7-b3ca1fda79cd", "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession\n\n# Initialize SparkSession with Hive support\nspark = SparkSession.builder \\\n    .appName(\"TableDemo\") \\\n    .enableHiveSupport() \\\n    .getOrCreate()\n\n# Read CSV from HDFS\nhdfs_path = \"/tmp/customers_1mb.csv\"  # Update path as per your HDFS location\ndf = spark.read.option(\"header\", True).csv(hdfs_path)\n\n# Show Data\ndf.show(5)\n\n# ---------------- Step 1: Create a Temporary Table (Session-based) ---------------- #\ndf.createOrReplaceTempView(\"temp_customers\")\n\nprint(\"### Querying Temporary Table (Exists only in this session) ###\")\nspark.sql(\"SELECT * FROM temp_customers LIMIT 5\").show()\n\n# ---------------- Step 2: Create a Global Temporary Table (Accessible across sessions) ---------------- #\ndf.createOrReplaceGlobalTempView(\"global_customers\")\n\nprint(\"### Querying Global Temporary Table ###\")\nspark.sql(\"SELECT * FROM global_temp.global_customers LIMIT 5\").show()\n\n# ---------------- Step 3: Create a Persistent Table (Stored in Hive Metastore) ---------------- #\nspark.sql(\"DROP TABLE IF EXISTS customers_persistent\")\ndf.write.mode(\"overwrite\").saveAsTable(\"customers_persistent\")\n\nprint(\"### Querying Persistent Table (Accessible across sessions and applications) ###\")\nspark.sql(\"SELECT * FROM customers_persistent LIMIT 5\").show()\n"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.8"}}, "nbformat": 4, "nbformat_minor": 5}