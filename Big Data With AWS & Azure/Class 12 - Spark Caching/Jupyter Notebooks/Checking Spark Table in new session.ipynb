{"cells": [{"cell_type": "code", "execution_count": 1, "id": "029ffd1e-39b0-467b-8c68-cc7e9925f916", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/02/02 03:27:11 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "from pyspark.sql import SparkSession\n\n# Start a new session (same application)\nspark = SparkSession.builder \\\n    .appName(\"TableVerification\") \\\n    .enableHiveSupport() \\\n    .getOrCreate()\n"}, {"cell_type": "code", "execution_count": 2, "id": "36ed8364-b4de-4b47-920a-8b9fbb79187d", "metadata": {}, "outputs": [], "source": "sparn_new = spark.newSession()"}, {"cell_type": "code", "execution_count": 3, "id": "8e6d058c-6144-4532-bad7-f2b5bf4ceaf8", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "### Querying Temporary Table (Should Fail) ###\n"}, {"name": "stderr", "output_type": "stream", "text": "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n"}, {"name": "stdout", "output_type": "stream", "text": "Temporary Table is not accessible in a new session!\n"}], "source": "\n# \u274c Temporary Table should NOT exist\nprint(\"### Querying Temporary Table (Should Fail) ###\")\ntry:\n    sparn_new.sql(\"SELECT * FROM temp_customers\").show()\nexcept Exception as e:\n    print(\"Temporary Table is not accessible in a new session!\")\n"}, {"cell_type": "code", "execution_count": 4, "id": "cfdb51bf-79ef-4d0c-9e5f-80be6313286c", "metadata": {}, "outputs": [{"data": {"text/html": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://my-cluster-m.us-central1-c.c.bigdata-project-448115.internal:37759\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>PySparkShell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ", "text/plain": "<pyspark.sql.session.SparkSession at 0x7f66779021d0>"}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": "sparn_new"}, {"cell_type": "code", "execution_count": 4, "id": "a8fd3a37-ec02-47aa-b2ca-d8ac4f1d2740", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "### Querying Global Temporary Table ###\n"}, {"ename": "AnalysisException", "evalue": "Table or view not found: global_temp.global_customers; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [global_temp, global_customers], [], false\n", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)", "\u001b[0;32m/tmp/ipykernel_12034/1652584772.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# \u2705 Global Temporary Table should exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"### Querying Global Temporary Table ###\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT * FROM global_temp.global_customers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery, **kwargs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0msqlQuery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mAnalysisException\u001b[0m: Table or view not found: global_temp.global_customers; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [global_temp, global_customers], [], false\n"]}], "source": "\n# \u2705 Global Temporary Table should exist\nprint(\"### Querying Global Temporary Table ###\")\nspark.sql(\"SELECT * FROM global_temp.global_customers\").show()\n\n\n"}, {"cell_type": "code", "execution_count": 5, "id": "d2aaf124-7a18-48c0-8d16-22ddc562449d", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "### Querying Global Temporary Table ###\n+---------+---------+-----------+\n|namespace|tableName|isTemporary|\n+---------+---------+-----------+\n+---------+---------+-----------+\n\n"}], "source": "print(\"### Querying Global Temporary Table ###\")\nsparn_new.sql(\"SHOW TABLES IN global_temp\").show()"}, {"cell_type": "code", "execution_count": 6, "id": "bd10e9d8-35fd-42d7-ab7c-250ffb6cb444", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "### Querying Persistent Table ###\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 0:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----------+-----------+---------+-----------+-------+-----------------+---------+\n|customer_id|       name|     city|      state|country|registration_date|is_active|\n+-----------+-----------+---------+-----------+-------+-----------------+---------+\n|          0| Customer_0|     Pune|Maharashtra|  India|       2023-06-29|    False|\n|          1| Customer_1|Bangalore| Tamil Nadu|  India|       2023-12-07|     True|\n|          2| Customer_2|Hyderabad|    Gujarat|  India|       2023-10-27|     True|\n|          3| Customer_3|Bangalore|  Karnataka|  India|       2023-10-17|    False|\n|          4| Customer_4|Ahmedabad|  Karnataka|  India|       2023-03-14|    False|\n|          5| Customer_5|Hyderabad|  Karnataka|  India|       2023-07-28|    False|\n|          6| Customer_6|     Pune|      Delhi|  India|       2023-08-29|    False|\n|          7| Customer_7|Ahmedabad|West Bengal|  India|       2023-12-28|     True|\n|          8| Customer_8|     Pune|  Karnataka|  India|       2023-06-22|     True|\n|          9| Customer_9|   Mumbai|  Telangana|  India|       2023-01-05|     True|\n|         10|Customer_10|     Pune|    Gujarat|  India|       2023-08-05|     True|\n|         11|Customer_11|    Delhi|West Bengal|  India|       2023-08-02|    False|\n|         12|Customer_12|  Chennai|    Gujarat|  India|       2023-11-21|    False|\n|         13|Customer_13|  Chennai|  Karnataka|  India|       2023-11-06|     True|\n|         14|Customer_14|Hyderabad| Tamil Nadu|  India|       2023-02-07|    False|\n|         15|Customer_15|   Mumbai|    Gujarat|  India|       2023-03-02|     True|\n|         16|Customer_16|  Chennai|  Karnataka|  India|       2023-04-05|    False|\n|         17|Customer_17|Hyderabad|West Bengal|  India|       2023-08-21|    False|\n|         18|Customer_18|     Pune|      Delhi|  India|       2023-10-04|     True|\n|         19|Customer_19|  Kolkata|    Gujarat|  India|       2023-02-05|     True|\n+-----------+-----------+---------+-----------+-------+-----------------+---------+\nonly showing top 20 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# \u2705 Persistent Table should exist\nprint(\"### Querying Persistent Table ###\")\nsparn_new.sql(\"SELECT * FROM customers_persistent\").show()"}, {"cell_type": "code", "execution_count": 8, "id": "4f3e6917-a466-4c81-937e-f54c172a51ed", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+--------------------+-----------+\n|namespace|           tableName|isTemporary|\n+---------+--------------------+-----------+\n|  default|customers_persistent|      false|\n+---------+--------------------+-----------+\n\n"}], "source": "sparn_new.sql('show tables').show()"}, {"cell_type": "code", "execution_count": 9, "id": "6a2904ff-b299-461f-892d-4abe2c6e44f9", "metadata": {}, "outputs": [], "source": "sparn_new.stop()"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.8"}}, "nbformat": 4, "nbformat_minor": 5}